{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotions: ['fear', 'surprise', 'sadness', 'happiness', 'anger', 'disgust'] \n",
      "\n",
      "fear: 25 # of images\n",
      "surprise: 83 # of images\n",
      "sadness: 28 # of images\n",
      "happiness: 69 # of images\n",
      "anger: 45 # of images\n",
      "disgust: 59 # of images\n",
      "\n",
      "Balanced Set:\n",
      "happiness: 45 # of images\n",
      "anger: 45 # of images\n",
      "Converting from array to PIL Image\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# CSE 253: Programming Assignment 1\n",
    "# Code snippet by Michael\n",
    "# Winter 2020\n",
    "################################################################################\n",
    "# We've provided you with the dataset in PA1.zip\n",
    "################################################################################\n",
    "# To install PIL, refer to the instructions for your system:\n",
    "# https://pillow.readthedocs.io/en/5.2.x/installation.html\n",
    "################################################################################\n",
    "# If you don't have NumPy installed, please use the instructions here:\n",
    "# https://scipy.org/install.html\n",
    "################################################################################\n",
    "\n",
    "from os import listdir\n",
    "import os, random, copy\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "''' \n",
    "list of face expressions (contempt, neutral are excluded) are:\n",
    "1. anger\n",
    "2. disgust\n",
    "3. fear\n",
    "4. happiness\n",
    "5. sadness\n",
    "6. surprise\n",
    "'''\n",
    "\n",
    "def load_data(data_dir=\"./aligned/\"):\n",
    "\t\"\"\" Load all PNG images stored in your data directory into a list of NumPy\n",
    "\tarrays.\n",
    "\n",
    "\tArgs:\n",
    "\t\tdata_dir: The relative directory path to the CK+ image directory.\n",
    "\tReturns:\n",
    "\t\timages: A dictionary with keys as emotions and a list containing images associated with each key.\n",
    "\t\tcnt: A dictionary that stores the # of images in each emotion\n",
    "\t\"\"\"\n",
    "\timages = defaultdict(list)\n",
    "\n",
    "\t# Get the list of emotional directory:\n",
    "\tfor e in listdir(data_dir):\n",
    "\t\t# excluding any non-directory files\n",
    "\t\tif not os.path.isdir(os.path.join(data_dir, e)):\n",
    "\t\t\tcontinue\n",
    "\t\t# Get the list of image file names\n",
    "\t\tall_files = listdir(os.path.join(data_dir, e))\n",
    "\n",
    "\t\tfor file in all_files:\n",
    "\t\t\t# Load only image files as PIL images and convert to NumPy arrays\n",
    "\t\t\tif '.png' in file:\n",
    "\t\t\t\timg = Image.open(os.path.join(data_dir, e, file))\n",
    "\t\t\t\timages[e].append(np.array(img))\n",
    "\n",
    "\tprint(\"Emotions: {} \\n\".format(list(images.keys())))\n",
    "\n",
    "\tcnt = defaultdict(int)\n",
    "\tfor e in images.keys():\n",
    "\t\tprint(\"{}: {} # of images\".format(e, len(images[e])))\n",
    "\t\tcnt[e] = len(images[e])\n",
    "\treturn images, cnt\n",
    "\n",
    "def balanced_sampler(dataset, cnt, emotions):\n",
    "\t# this ensures everyone has the same balanced subset for model training, don't change this seed value\n",
    "\trandom.seed(20)\n",
    "\tprint(\"\\nBalanced Set:\")\n",
    "\tmin_cnt = min([cnt[e] for e in emotions])\n",
    "\tbalanced_subset = defaultdict(list)\n",
    "\tfor e in emotions:\n",
    "\t\tbalanced_subset[e] = copy.deepcopy(dataset[e])\n",
    "\t\trandom.shuffle(balanced_subset[e])\n",
    "\t\tbalanced_subset[e] = balanced_subset[e][:min_cnt]\n",
    "\t\tprint('{}: {} # of images'.format(e, len(balanced_subset[e])))\n",
    "\treturn balanced_subset\n",
    "\n",
    "def display_face(img):\n",
    "\t\"\"\" Display the input image and optionally save as a PNG.\n",
    "\n",
    "\tArgs:\n",
    "\t\timg: The NumPy array or image to display\n",
    "\n",
    "\tReturns: None\n",
    "\t\"\"\"\n",
    "\t# Convert img to PIL Image object (if it's an ndarray)\n",
    "\tif type(img) == np.ndarray:\n",
    "\t\tprint(\"Converting from array to PIL Image\")\n",
    "\t\timg = Image.fromarray(img)\n",
    "\n",
    "\t# Display the image\n",
    "\timg.show()\n",
    "\n",
    "\n",
    "# example on how to use it\n",
    "if __name__ == '__main__':\n",
    "\t# The relative path to your image directory\n",
    "\tdata_dir = \"./aligned/\"\n",
    "\tdataset, cnt = load_data(data_dir)\n",
    "\t# test with happiness and anger\n",
    "\timages = balanced_sampler(dataset, cnt, emotions=['happiness', 'anger'])\n",
    "\tdisplay_index = 0\n",
    "\tdisplay_face(images['happiness'][display_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotions: ['fear', 'surprise', 'sadness', 'happiness', 'anger', 'disgust'] \n",
      "\n",
      "fear: 25 # of images\n",
      "surprise: 83 # of images\n",
      "sadness: 28 # of images\n",
      "happiness: 69 # of images\n",
      "anger: 45 # of images\n",
      "disgust: 59 # of images\n",
      "\n",
      "Balanced Set:\n",
      "happiness: 45 # of images\n",
      "anger: 45 # of images\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "\n",
    "data_dir = \"./aligned/\"\n",
    "dataset, cnt = load_data(data_dir)\n",
    "images = balanced_sampler(dataset, cnt, emotions=['happiness', 'anger'])\n",
    "image_list = []\n",
    "label_list = []\n",
    "\n",
    "for k in images.keys():\n",
    "    image_list = image_list + [i.flatten() for i in images[k]]\n",
    "    label_list = label_list + [k] * len(images[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "\n",
    "image_matrix = np.matrix(image_list)\n",
    "average_face = np.mean(image_list, axis=0)\n",
    "centered_faces = image_matrix - average_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "\n",
    "A_T = centered_faces\n",
    "A = A_T.T\n",
    "\n",
    "eigenvalues, eigenvectors = np.linalg.eig(np.dot(A_T, A) / len(centered_faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "\n",
    "temp1 = np.dot(A, eigenvectors[:, 0]).flatten().A1\n",
    "temp2 = []\n",
    "for i in range(len(centered_faces)):\n",
    "    temp2.append(np.dot(centered_faces[i].flatten(), temp1) / np.linalg.norm(temp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.063298011819522e-14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "\n",
    "np.mean(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7167.627600644913"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "\n",
    "np.std(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7167.627600644913"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "\n",
    "np.sqrt(eigenvalues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.13748854e+07,  1.31720472e+07,  1.09666105e+07,  5.05977225e+06,\n",
       "        4.67201550e+06,  3.38150872e+06,  2.89461627e+06,  2.75973836e+06,\n",
       "        2.16073590e+06,  1.64192184e+06,  1.48691412e+06,  1.41797916e+06,\n",
       "        1.36143449e+06,  1.20431420e+06,  1.10997722e+06,  1.00777648e+06,\n",
       "        9.63367124e+05,  8.80241423e+05,  8.46418304e+05,  7.97733814e+05,\n",
       "        7.55831827e+05,  7.18708430e+05,  7.07558784e+05,  6.50850130e+05,\n",
       "        6.19597681e+05,  5.80856280e+05,  5.50018774e+05,  5.24190625e+05,\n",
       "        4.95576346e+05,  4.64368414e+05,  4.48087248e+05,  4.22332477e+05,\n",
       "        4.03557407e+05,  3.94927212e+05,  3.80202268e+05,  3.62898366e+05,\n",
       "       -9.68541420e-10,  3.52461831e+05,  3.42034312e+05,  3.34918055e+05,\n",
       "        3.23272288e+05,  3.11268309e+05,  3.00230258e+05,  2.95037060e+05,\n",
       "        2.90617316e+05,  2.72512344e+05,  5.24749462e+04,  5.70487584e+04,\n",
       "        6.68651927e+04,  2.51743483e+05,  2.53577075e+05,  2.44417132e+05,\n",
       "        2.38720882e+05,  2.26626389e+05,  7.44420518e+04,  7.54631251e+04,\n",
       "        2.16062826e+05,  2.11458269e+05,  2.07106228e+05,  8.00325172e+04,\n",
       "        8.42389742e+04,  8.72372700e+04,  9.04240714e+04,  9.46595785e+04,\n",
       "        1.96813744e+05,  1.89849963e+05,  1.85233719e+05,  9.74837753e+04,\n",
       "        1.00436147e+05,  1.98118545e+05,  1.80303289e+05,  1.68992183e+05,\n",
       "        1.04083677e+05,  1.64669448e+05,  1.56981917e+05,  1.45598860e+05,\n",
       "        1.26330597e+05,  1.51415017e+05,  1.40031420e+05,  1.34042962e+05,\n",
       "        1.18371470e+05,  1.08956075e+05,  1.77027076e+05,  1.21075896e+05,\n",
       "        1.12601775e+05,  1.07494186e+05,  1.63011045e+05,  1.31903082e+05,\n",
       "        1.12124003e+05,  1.42091097e+05])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-0.01039252, -0.00757324,  0.02254468, ...,  0.02280489,\n",
       "         -0.0368005 ,  0.01045888],\n",
       "        [-0.04868878,  0.01409995, -0.00412422, ..., -0.00874747,\n",
       "          0.01864785, -0.01424208],\n",
       "        [-0.04787329,  0.0848464 ,  0.05973986, ..., -0.05920861,\n",
       "          0.06270736,  0.15445455],\n",
       "        ...,\n",
       "        [ 0.1242187 ,  0.07442512, -0.04833889, ...,  0.03360136,\n",
       "          0.02711739, -0.20879242],\n",
       "        [ 0.14175137, -0.12896323, -0.01600848, ...,  0.03951139,\n",
       "         -0.04184454, -0.03478323],\n",
       "        [ 0.15816625,  0.12411903,  0.05540458, ..., -0.06572582,\n",
       "          0.10596617,  0.05926731]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
